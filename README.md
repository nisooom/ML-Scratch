# Machine Learning from Scratch in C++

## Overview
This project implements various basic machine learning models from scratch using C++. The goal is to provide a foundational understanding of machine learning concepts and algorithms by coding them directly in C++, without relying on external libraries or frameworks. This is an ongoing project, and new models and features will be added over time.

## Table of Contents
- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Implemented Models](#implemented-models)
- [Ongoing Development](#ongoing-development)

## Introduction
Machine learning is a rapidly growing field that enables computers to learn from data and make predictions or decisions. This project focuses on implementing fundamental machine learning algorithms, including linear regression, logistic regression, decision trees, k-nearest neighbors, and more. By coding these algorithms from scratch, users can gain a deeper understanding of how they work and their underlying mathematical principles.

## Installation
To set up the project on your local machine, follow these steps:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/nisooom/ML-Scratch.git
   cd ML-Scratch
   ```

2. **Compile the project**:
   Use a C++ compiler (like g++) to compile the source files.
   ```bash
    make
   ```

3. **Run the Models**:
    You can find all the executables in the ```out/``` directory

## Usage
You can find all the model examples in the ```examples/``` directory, you can change the parameters and run the ```make``` command again to recompile your changes.

## Implemented Models

### 1. Linear Regression
Linear regression is used for predicting a continuous target variable based on one or more predictor variables. The implementation includes:
- Calculation of predictions based on learned coefficients.

### 2. Logistic Regression
Logistic regression is used for binary classification tasks. It predicts the probability that a given input belongs to a particular class using the sigmoid function.
- Gradient descent optimization.


## Ongoing Development
This project is continuously evolving! New algorithms, enhancements, and features will be added regularly as part of ongoing development efforts. Contributions are encouraged, and users can expect updates that improve functionality and expand model coverage over time.

